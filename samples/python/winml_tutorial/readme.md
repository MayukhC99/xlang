# Tutorial: Create a Windows Machine Learning application with Python/WinRT

This tutorial is a port of the [WinML C++/WinRT tutorial](https://docs.microsoft.com/en-us/windows/ai/get-started-desktop) to Python. Please review the original documentation for background on WinML. This document will only focus on the differences related to using Python/WinRT instead of C++/WinRT.

> Note, xlang in general and Python/WinRT is very, very early in its development. It is not ready for general usage building Python applications against Windows Runtime APIs. Many features are missing or will be changed while development continues. Only the core scenario described below has been tested end-to-end. You are encouraged to experiment outside the bounds of the core scenario described in this document. Please [open issues](https://github.com/Microsoft/xlang/issues) when (not if!) you find bugs or missing functionality.

## Prerequisites

* [Visual Studio 2017](https://developer.microsoft.com/windows/downloads), version 15.8 or later.
  * This tutorial was tested against Visual Studio 15.8.7, the latest version as of this writing.
    * Visual Studio's Desktop Development with C++ workload installation is required.
* [Windows 10](https://developer.microsoft.com/windows/downloads), version 1809 or later.
* [Python for Windows](https://www.python.org), version 3.6 or later
  * Visual Studio's Python Development workload is _not_ required, but does include Python 3.6. This tutorial is written assuming Python 3.6 is available in the VS 2017 Developer Command Prompt.

## Step 1 - Compile the Python/WinRT Generated Code

The pywinrt_output folder contains C++ files generated by the Python/WinRT tool from the [xlang project](https://github.com/Microsoft/xlang).

> At this time, the Python/WinRT tool is only distributed as source code.This sample includes the output generated by Python/WinRT to enable the reader to complete the tutorial without needing to build the Python/WinRT tool. A [seperate document](readme-advanced.md) details how this code was generated for those wishing to experiment futher with Python/WinRT in its current state.

To build the Python native extension module, open a VS 2017 developer command prompt, change to the /pywinrt_output directory and execute the following command:

``` cmd
py setup.py build
```

This step will build the extension module using [Python's setuptools package](https://github.com/pypa/setuptools). The resulting compiled module will be named `_pyrt.cp36-win_amd64.pyd` and will be available in the `/pywinrt_output/build/lib.win-amd64-3.6/` directory.

## Step 2 - Add Generated Python/WinRT Extension Module to sys.path

Now that the Python/WinRT extension module has been compiled, the Python interpreter needs to know how to find it. Create a new python file in the same folder that contains the /python_output folder and add the following code at the top of it.

> Note, winml_tutorial.py containst the complete code for this tutorial, if you'd rather just follow along and not type the code in yourself.

``` python
import sys
vi = sys.version_info
dirname = "lib.{2}-{0}.{1}".format(vi.major, vi.minor, "win-amd64" if sys.maxsize > 2**32 else "win32")
test_module_path = "./pywinrt_output/build/" + dirname
sys.path.append(str(test_module_path))
```

## Step 3 - Load the WinML Model

Now that the Python/WinRT extension module has been added to the Python interpreter's path, it can be used from Python directly. Now, we will use the [LearningModel.LoadFromFilePath](https://docs.microsoft.com/uwp/api/windows.ai.machinelearning.learningmodel.loadfromfilepath) API to load the ONNX model from disk, as per the [load the model](https://docs.microsoft.com/en-us/windows/ai/get-started-desktop#load-the-model) step from the original tutorial.

First, instead of manually adding timing code to every function like the C++/WinRT version does, let's add a [Python decorator](https://docs.python.org/3.7/glossary.html#term-decorator) so we only have to write this code once.

``` python
def timed_op(fun):
    import time

    def wrapper(*args, **kwds):

        ret = fun(*args, **kwds)

        end = time.perf_counter()
        print(fun.__name__, "took", end - start, "seconds")
        return ret

    return wrapper
```

With our timed_op decorator, LoadModel in Python is a trivial, one-line function.

> Note, WinRT namespaces are currently flattened for use from Python. Full namespace support will come in a future update to Python/WinRT.

``` python
import _pyrt

@timed_op
def load_model(model_path):
    return _pyrt.LearningModel.LoadFromFilePath(model_path)
```

We can call our load_model function from the main part of our python script.

``` python
import os.path

_pyrt.init_apartment()
model = load_model(os.path.abspath("./winml_content/SqueezeNet.onnx"))
```

Running this code from Python now should result in something similar to the following (the time it takes to load the model will vary).

``` cmd
C:\Users\user\Source\aitutorial>py aitutorial.py

Starting load_model
load_model took 0.7060564 seconds
```

## Step 4 - Load the Image to Evaluate

Next, we'll [load an image](https://docs.microsoft.com/en-us/windows/ai/get-started-desktop#load-the-image) that we are going to evaluate with the loaded model.

This step requires the use of async WinRT methods. Automatic projection of WinRT async methods as a [Python awaitable](https://docs.python.org/3.7/glossary.html#term-awaitable) is not complete, so we need some helper code to do this conversion.

``` python
import asyncio
import _pyrt

def timed_op(fun):
    import time

    def sync_wrapper(*args, **kwds):
        print("Starting", fun.__name__)
        start = time.perf_counter()

        ret = fun(*args, **kwds)

        end = time.perf_counter()
        print(fun.__name__, "took", end - start, "seconds")
        return ret

    async def async_wrapper(*args, **kwds):
        print("Starting", fun.__name__)
        start = time.perf_counter()

        ret = await fun(*args, **kwds)

        end = time.perf_counter()
        print(fun.__name__, "took", end - start, "seconds")
        return ret

    return async_wrapper if asyncio.iscoroutinefunction(fun) else sync_wrapper

async def wrap_async_op(op):
    loop = asyncio.get_event_loop()
    future = loop.create_future()

    def callback(operation, status):
        if status == 1:
            result = operation.GetResults()
            loop.call_soon_threadsafe(asyncio.Future.set_result, future, result)
        elif status == 2:
            loop.call_soon_threadsafe(asyncio.Future.set_exception, future, asyncio.CancelledError())
        elif status == 3:
            loop.call_soon_threadsafe(asyncio.Future.set_exception, future, RuntimeError("AsyncOp failed"))
        else:
            loop.call_soon_threadsafe(asyncio.Future.set_exception, future, RuntimeError("Unexpected AsyncStatus"))

    op.put_Completed(callback)

    return await future

def run_async_code(code):
    loop = asyncio.get_event_loop()
    loop.run_until_complete(code())
    loop.close()
```

The first function in the previous code block is an updated version of the timed_op decorator, this one that can time async functions as well as normal ones.

The second function, wrap_async_op, converts a WinRT IAsyncOperation into a Python awaitable using [asyncio.Future](https://docs.python.org/3.7/library/asyncio-future.html).

The final function, run_async_code, simply enables syncronous code (such as our main block of program execution) to call an async function.

With these helpers now in place, we can write async python code to load an image and convert it into a VideoFrame for use with the LearningModel we created earlier.

> Note, WinRT enumerations are currently projected as integers in Python. Full Python enumeration support will come in a future update to Python/WinRT.

``` python
@timed_op
async def load_image_file(file_path):
    file = await wrap_async_op(_pyrt.StorageFile.GetFileFromPathAsync(file_path))
    stream = await wrap_async_op(file.OpenAsync(0)) # 0 == FileAccessMode::Read
    decoder = await wrap_async_op(_pyrt.BitmapDecoder.CreateAsync(stream))
    software_bitmap = await wrap_async_op(decoder.GetSoftwareBitmapAsync())
    return _pyrt.VideoFrame.CreateWithSoftwareBitmap(software_bitmap)
```

In order to intermix syncronous and asyncronous code, we will move our main block of program exectuion into an async function, which we can then call from a syncronous context using run_async_code:

``` python
async def async_main():
    import os.path

    model_path = os.path.abspath("./winml_content/SqueezeNet.onnx")
    model = load_model(model_path)

    image_file = os.path.abspath("./winml_content/kitten_224.png")
    image_frame = await load_image_file(image_file)

_pyrt.init_apartment()
run_async_code(async_main)
```

Running this code from Python now should result in something similar to the following (again, timings will vary).

``` cmd
C:\Users\user\Source\aitutorial>py aitutorial.py
Starting load_model
load_model took 0.7183248 seconds
Starting load_image_file
load_image_file took 0.17086919999999994 seconds
```

## Step 5 - Bind Input and Output

Now that the model and image to be evaluated are loaded, we can create a LearningModelSession to [bind them together](https://docs.microsoft.com/en-us/windows/ai/get-started-desktop#bind-the-input-and-output).

``` python
@timed_op
def bind_model(model, image_frame):
    device = _pyrt.LearningModelDevice(0) # 0 == LearningModelDeviceKind::Default
    session = _pyrt.LearningModelSession(model, device)
    binding = _pyrt.LearningModelBinding(session)
    image_feature_value = _pyrt.ImageFeatureValue.CreateFromVideoFrame(image_frame)
    binding.Bind("data_0", image_feature_value)
    shape = _pyrt.TensorFloat.Create([1, 1000, 1, 1])
    binding.Bind("softmaxout_1", shape)
    return (session, binding)
```

Instead of using global variables like the C++/WinRT version, this Python code is passing all state as parameters and return values. In bind_model, we need to return two values - the session and the binding - so we group them into a tuple.

We can simply add the bind_model call to our existing async_main function, using destructuring assignment to assign the grouped return values into seperate variables.

``` python
async def async_main():
    import os.path

    model_path = os.path.abspath("./winml_content/SqueezeNet.onnx")
    model = load_model(model_path)

    image_file = os.path.abspath("./winml_content/kitten_224.png")
    image_frame = await load_image_file(image_file)

    session, binding = bind_model(model, image_frame)
```

Running this code with Python now should result in something similar to the following (again, timings will vary).

``` cmd
C:\Users\user\Source\aitutorial>py aitutorial.py
Starting load_model
load_model took 0.7168329999999999 seconds
Starting load_image_file
load_image_file took 0.1684 seconds
Starting bind_model
bind_model took 0.020646799999999965 seconds
```

## Step 6 - Evaluate the Model

We are now ready to [evaluate the model](https://docs.microsoft.com/en-us/windows/ai/get-started-desktop#evaluate-the-model) and find out what the image represents.

> Note, WinRT properties are currently projected as get/put methods in Python. Full Python property support will come in a future update to Python/WinRT.

``` python
@timed_op
def evaluate_model(session, binding):
    results = session.Evaluate(binding, "RunId")
    o = results.get_Outputs().Lookup("softmaxout_1")
    result_tensor = _pyrt.TensorFloat._from(o)
    return result_tensor.GetAsVectorView()
```

The [Evaluate method](https://docs.microsoft.com/en-us/uwp/api/windows.ai.machinelearning.learningmodelsession.evaluate) returns its [Outputs](https://docs.microsoft.com/en-us/uwp/api/windows.ai.machinelearning.learningmodelevaluationresult.outputs) as a string to object IMap. To convert the result back to the expected type (TesorFloat in this case), we use the _from method. While Python types are typically dynamically types (sometimes called "duck typing"), WinRT types are statically typed. Thus the need to convert the softmaxout_1 output object to the correct type in order to work with it.

Adding this to async_main is a simple one line addition:

``` python
async def async_main():
    import os.path

    model_path = os.path.abspath("./winml_content/SqueezeNet.onnx")
    model = load_model(model_path)

    image_file = os.path.abspath("./winml_content/kitten_224.png")
    image_frame = await load_image_file(image_file)

    session, binding = bind_model(model, image_frame)
    results = evaluate_model(session, binding)
```

Running this code with Python now should result in something similar to the following (again, timings will vary).

``` cmd
Starting load_model
load_model took 0.7029269 seconds
Starting load_image_file
load_image_file took 0.15494339999999995 seconds
Starting bind_model
bind_model took 0.016178600000000043 seconds
Starting evaluate_model
evaluate_model took 0.022036400000000067 seconds
```

## Step 7 - Printing the Results

Finally, we need to print the model evaluation results. The possible model results are stored in a comma-seperated file named labels.txt. Loading this data in Python is straightforward:

``` python
def load_labels(labels_path):
    import csv
    labels = dict()
    with open(labels_path) as labels_file:
        labels_reader = csv.reader(labels_file)
        for label in labels_reader:
            label_text = ', '.join(label[1:])
            labels[int(label[0])] = ', '.join(label[1:])
    return labels
```

`load_labels` returns a Python dictionary mapping model results to a text string. All that remains now is to loop thru the results, looking for the top three probabilities and then print them out.

``` python
def print_results(results, labels):
    topProbabilities = [0.0 for x in range(3)]
    topProbabilityLabelIndexes = [0 for x in range(3)]

    for i in range(results.get_Size()):
        for j in range(3):
            result = results.GetAt(i)
            if result > topProbabilities[j]:
                topProbabilityLabelIndexes[j] = i
                topProbabilities[j] = result
                break

    print()
    for i in range(3):
        print(labels[topProbabilityLabelIndexes[i]], "with confidence of", topProbabilities[i])

async def async_main():
    import os.path

    model_path = os.path.abspath("./winml_content/SqueezeNet.onnx")
    model = load_model(model_path)

    image_file = os.path.abspath("./winml_content/kitten_224.png")
    image_frame = await load_image_file(image_file)

    session, binding = bind_model(model, image_frame)
    results = evaluate_model(session, binding)

    labels_path = os.path.abspath("./winml_content/Labels.txt")
    labels = load_labels(labels_path)

    print_results(results, labels)
```

Executing this code with Python one final time should reveal the results of the model evaluation, predicting that the image is a tabby cat.

``` cmd
C:\Users\hpierson\Source\xlang\src\test\python>py aitutorial.py
Starting load_model
load_model took 0.7041156000000001 seconds
Starting load_image_file
load_image_file took 0.1883804 seconds
Starting bind_model
bind_model took 0.01686500000000002 seconds
Starting evaluate_model
evaluate_model took 0.021589099999999917 seconds

tabby,  tabby cat with confidence of 0.931460976600647
Egyptian cat with confidence of 0.06530658155679703
Persian cat with confidence of 0.00019303907174617052
```
